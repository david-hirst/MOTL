---
title: "TL with ProjectR"
output: html_document
---

```{r}
.libPaths("/home/david/R/x86_64-pc-linux-gnu-library/4.2")
```

The purpose of this script is to:
Import a MOFA model trained on learning set
Use projectR to infer scores for the target set
Factors are were not dropped during the simulation study

The script loops through simulation instances for a given configuration

Load packages

```{r}
library(ggplot2)
library(MOFA2)
library(rhdf5)
library(rjson)
library(projectR)
```

Specify which simulation and factorization configurations to import
Also specify whether to center and scale the target dataset before the projection.
If centering is selected, this is done with feature menas and standard deviations from the learning dataset

```{r}
Config = "SimConfig1"
scale_views = 'False'
center_groups = 'True'
FactorSelection = 'ActiveK'
CenterScaleTrg = TRUE #center scale the target set before projection?
```

Specify global paths

```{r}
BaseDir = getwd() # or change it to somewhere else
InputDir = file.path(BaseDir, Config)

# MOFA learning dataset factorizations directory
FctrznsDir = file.path(InputDir,
                       paste0("Fctrzn_Lrn","_scale_",scale_views,"_center_",center_groups,"_",FactorSelection))

# output directory for ProjectR results
# will depend on whether centered and scaled first

if (CenterScaleTrg){
  TLFctrznsDir = file.path(InputDir,
                       paste0("TL","_scale_",scale_views,"_center_",center_groups,"_",FactorSelection,"_ProjectR_CS"))
} else {
  TLFctrznsDir = file.path(InputDir,
                       paste0("TL","_scale_",scale_views,"_center_",center_groups,"_",FactorSelection,"_ProjectR"))
}

if (!dir.exists(TLFctrznsDir)){
  dir.create(TLFctrznsDir)
}


```


Import metadata related to simulations and factorizations

```{r}
SimMeta = fromJSON(file = file.path(InputDir,"sim_meta.json"))
M = length(SimMeta$D)
YDists = SimMeta$YDists
Sims = SimMeta$Sims
```


Loop through simulations and use the ProjectR for transfer learning
As simulation and factorization was done in python the simulation and dataset numbers start at 0

```{r}
for (sim in 1:Sims-1){

  # simulation, factorization and transfer learning directories
  SimDir = file.path(InputDir,"SimData",paste0("sim",sim))
  FctrznDir = file.path(FctrznsDir,paste0("Fctrzn",sim))
  TLFctrznDir = file.path(TLFctrznsDir,paste0("TL",sim))
  if (!dir.exists(TLFctrznDir)){
    dir.create(TLFctrznDir)
  }
  
  # load simulated data for the target set
  
  IfLrn = read.csv(file.path(SimDir,"IfLrn.csv"),header=FALSE)
  IfLrn = as.vector(IfLrn$V1)
  
  SimY = vector("list")
  for (i in 1:M-1){
    SimY[[i+1]] = read.csv(file.path(SimDir,paste0("Y",i,".csv")),header = FALSE)
    SimY[[i+1]] = as.matrix(SimY[[i+1]][IfLrn==0,])
  }
  
  # load feature variances for filtering
  
  FVarTrg = vector("list")
  for (i in 1:M-1){
    FVarTrg[[i+1]] = as.vector(read.csv(file.path(SimDir,paste0("FVarTrgY",i,".csv")),header = FALSE)$V1)
  }
  
  # Load the model and information about what features were used in factorization
  
  InputModel = file.path(FctrznDir,"Model.hdf5")
  Fctrzn = load_model(file = InputModel)
  FVarKp = vector("list")
  for (i in 1:M-1){
    FVarKp[[i+1]] = as.vector(read.csv(file.path(FctrznDir,paste0("FVarKp_m",i,"g_0.csv")),header = FALSE)$V1)
  }
  
  # Only include features that were included in the learning set factorization and 
  # have variance > 0 in the target set
  
  TrgKp = vector("list")
  for (i in 1:M){
    TrgKp[[i]] = (FVarTrg[[i]] > 0) & (FVarKp[[i]] == 1)
  }
  
  LrnKp = vector("list")
  for (i in 1:M){
    LrnKp[[i]] = FVarTrg[[i]][FVarKp[[i]] == 1] > 0
  }
  
  # filter the weight matrices from the learning set factorization
  # then concatenate into a single weight matrix
  
  Fctrzn_Lrn_W = vector("list")
  for (i in 1:M){
    Fctrzn_Lrn_W[[i]] = Fctrzn@expectations$W[[i]][LrnKp[[i]],]
  }
  Fctrzn_Lrn_W_Ccnt = do.call(rbind,Fctrzn_Lrn_W)
  
  # means and standard deviations from learning data for scaling and centering
  Fctrzn_Lrn_Means = vector("list")
  Fctrzn_Lrn_SDs = vector("list")
  
  for (i in 1:M){
    
    if (as.vector(Fctrzn@model_options$likelihoods)[i]=="gaussian"){
      Fctrzn_Lrn_Means[[i]] = as.vector(Fctrzn@intercepts[[i]]$group0)[LrnKp[[i]]]
    } else {
      Fctrzn_Lrn_Means[[i]] = as.vector(rowMeans(Fctrzn@data[[i]]$group0))[LrnKp[[i]]]
    }
    
    Fctrzn_Lrn_SDs[[i]] = as.vector(apply(Fctrzn@data[[i]]$group0,1,sd))[LrnKp[[i]]]
    
  }
  
  # transform and concatenate target set
  
  SimY_Trnsfm = vector("list")
  for (i in 1:M){
    
    if (CenterScaleTrg){
      SimY_Trnsfm[[i]] = t(
      sweep(
      sweep(SimY[[i]][,TrgKp[[i]]],2,Fctrzn_Lrn_Means[[i]],"-"),2,Fctrzn_Lrn_SDs[[i]],"/"
    )
    )
    } else {
      SimY_Trnsfm[[i]] = t(SimY[[i]][,TrgKp[[i]]])
    }
    
  }
  SimY_Trnsfm_Ccnt = do.call(rbind,SimY_Trnsfm)
  
  ## use projectR to get scores for the target set
  
  row.names(SimY_Trnsfm_Ccnt) = row.names(Fctrzn_Lrn_W_Ccnt)
  
  fit_start_time = Sys.time()
  ZProjectR = projectR(data = SimY_Trnsfm_Ccnt, loadings = Fctrzn_Lrn_W_Ccnt)
  fit_end_time = Sys.time()
  
  # export the data used in the fit
  TL_ProjectR_data = list(
    "TrgKp" = TrgKp,
    "Fctrzn_Lrn_W_fltrd" = Fctrzn_Lrn_W,
    "ZProjectR" = ZProjectR,
    "fit_start_time" = fit_start_time,
    "fit_end_time" = fit_end_time,
    "CenterScaleTrg" = CenterScaleTrg
  )
  
  saveRDS(TL_ProjectR_data,file.path(TLFctrznDir,"TL_ProjectR_data.rds"))
  
}
```


